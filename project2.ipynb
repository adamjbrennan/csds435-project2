{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\charl\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\charl\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\charl\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\charl\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\charl\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\charl\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\charl\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\charl\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\charl\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\charl\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\charl\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\charl\\anaconda3\\lib\\site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "# Install missing packages to kernel.\n",
    "\n",
    "! pip install pandas\n",
    "! pip install scikit-learn\n",
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.set_option('display.max_rows', 10)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSDS-435: Project #2\n",
    "# Adam Brennan and Charlie Song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_health_tweets_dataframe():\n",
    "    # read in the cnnhealth.txt file using utf-8 encoding\n",
    "    with open('cnnhealth.txt', 'r', encoding='utf-8') as cnn_health_tweets_dataset:\n",
    "        # initialize empty list to store tweets\n",
    "        tweets = []\n",
    "\n",
    "        # for each row in the dataset, skip the first two columns and append the tweet to the tweets list\n",
    "        for row in cnn_health_tweets_dataset:\n",
    "            columns = row.strip().split('|')\n",
    "            tweet = '|'.join(columns[2:])\n",
    "            tweets.append([tweet])\n",
    "\n",
    "    # convert list of tweets to pandas DataFrame\n",
    "    df = pd.DataFrame(tweets, columns=['tweet'])\n",
    "    \n",
    "    # return the resulting pandas DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_of_words_matrix(tweets_list):\n",
    "    # initialize CountVectorizer opbject \n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    # build bag of words matrix from tweets list\n",
    "    bag_of_words_matrix = vectorizer.fit_transform(tweets_list)\n",
    "    \n",
    "    return bag_of_words_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_of_words_dataframe(tweets_list):\n",
    "    # initialize CountVectorizer opbject \n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    # build bag of words matrix from tweets list\n",
    "    bag_of_words_matrix = vectorizer.fit_transform(tweets_list)\n",
    "\n",
    "    # convert bag of words matrix to a pandas DataFrame\n",
    "    bag_of_words_df = pd.DataFrame(bag_of_words_matrix.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "    \n",
    "    return bag_of_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet(tweets_df, tweet_index):\n",
    "    # return the tweet at the specified index in string form\n",
    "    return str(tweets_df.iloc[tweet_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_total_tokens(tweets_list):\n",
    "    num_total_tokens = 0\n",
    "\n",
    "    for tweet in tweets_list:\n",
    "        num_total_tokens += len(tweet)\n",
    "\n",
    "    return num_total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_summary_dataframe(tweets_list):\n",
    "    num_tweets = len(tweets_list)\n",
    "    num_total_tokens = get_num_total_tokens(tweets_list)\n",
    "    num_unique_tokens = get_bag_of_words_dataframe(tweets_list).shape[1]\n",
    "    num_avg_tokens_per_tweet = num_total_tokens / num_tweets\n",
    "\n",
    "    data = [[num_tweets, num_total_tokens, num_unique_tokens, num_avg_tokens_per_tweet, 'CNN Health Tweets']]\n",
    "\n",
    "    columns = ['# Tweets', '# Total Tokens', '# Unique Tokens', 'Avg. Tokens Per Tweet', 'Description']\n",
    "\n",
    "    tweets_summary_dataframe = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    return tweets_summary_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance(bag_of_words_matrix):\n",
    "    bag_of_words_matrix_ed = euclidean_distances(bag_of_words_matrix)\n",
    "\n",
    "    np.savetxt(\"euclidean_distance.txt\", bag_of_words_matrix_ed, delimiter=',', fmt='%.2f')\n",
    "\n",
    "    return bag_of_words_matrix_ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(bag_of_words_matrix):\n",
    "    bag_of_words_matrix_cs = cosine_similarity(bag_of_words_matrix)\n",
    "\n",
    "    np.savetxt(\"cosine_similarity.txt\", bag_of_words_matrix_cs, delimiter=',', fmt='%.2f')\n",
    "\n",
    "    return bag_of_words_matrix_cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the \"cnnhealth.txt\" file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An abundance of online info can turn us into e-hypochondriacs. Or, worse, lead us to neglect getting the care we need http://cnn.it/1L1t1Fv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A plant-based diet that incorporates fish may be the key to preventing colorectal cancers: http://cnn.it/1xdpsjT http://pbs.twimg.com/media/CAARHEGWEAAJGz6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It doesn't take much to damage your hearing at a sports bar or nightclub. That's why a billion people are at risk. http://cnn.it/1BOphBk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @CNN: Forever young? Discover this island’s secrets to longevity on #TheWonderList w/ @BillWeirCNN  http://cnn.it/1GNdmqc https://t.co/…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @CNN: Is post-traumatic stress disorder in your genes? A simple blood test may one day help tell you http://cnn.it/1xls8w5 http://t.co/…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>RT @EverydayHealth: Want killer abs? @JillianMichaels shows you how get them: http://at.cnn.com/ubAkAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>Medicare at stake -- @sanjayguptaCNN talks about politicians' plans http://at.cnn.com/7nLSOm7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>Ann Romney talks about her experience with MS http://at.cnn.com/khb6keC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>Make sure your first marathon isn't your last! http://at.cnn.com/liehiPl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>Robin Roberts' cancer diagnosis http://at.cnn.com/XNq3fhk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4061 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                tweet\n",
       "0                         An abundance of online info can turn us into e-hypochondriacs. Or, worse, lead us to neglect getting the care we need http://cnn.it/1L1t1Fv\n",
       "1     A plant-based diet that incorporates fish may be the key to preventing colorectal cancers: http://cnn.it/1xdpsjT http://pbs.twimg.com/media/CAARHEGWEAAJGz6.jpg\n",
       "2                            It doesn't take much to damage your hearing at a sports bar or nightclub. That's why a billion people are at risk. http://cnn.it/1BOphBk\n",
       "3                         RT @CNN: Forever young? Discover this island’s secrets to longevity on #TheWonderList w/ @BillWeirCNN  http://cnn.it/1GNdmqc https://t.co/…\n",
       "4                         RT @CNN: Is post-traumatic stress disorder in your genes? A simple blood test may one day help tell you http://cnn.it/1xls8w5 http://t.co/…\n",
       "...                                                                                                                                                               ...\n",
       "4056                                                           RT @EverydayHealth: Want killer abs? @JillianMichaels shows you how get them: http://at.cnn.com/ubAkAN\n",
       "4057                                                                    Medicare at stake -- @sanjayguptaCNN talks about politicians' plans http://at.cnn.com/7nLSOm7\n",
       "4058                                                                                          Ann Romney talks about her experience with MS http://at.cnn.com/khb6keC\n",
       "4059                                                                                         Make sure your first marathon isn't your last! http://at.cnn.com/liehiPl\n",
       "4060                                                                                                        Robin Roberts' cancer diagnosis http://at.cnn.com/XNq3fhk\n",
       "\n",
       "[4061 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get pandas DataFrame\n",
    "tweets_df = get_cnn_health_tweets_dataframe()\n",
    "\n",
    "# display DataFrame\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tweet as list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of tweets\n",
    "tweets_list = tweets_df['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the \"bag of words\" pandas DataFrame using the previously generated tweets pandas DataFrame..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>008relo</th>\n",
       "      <th>00fvvdw</th>\n",
       "      <th>00igyua</th>\n",
       "      <th>01</th>\n",
       "      <th>01tdt1o</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>zwwtu7</th>\n",
       "      <th>zxodiqo</th>\n",
       "      <th>zy53fec</th>\n",
       "      <th>zy7u11</th>\n",
       "      <th>zyam2xi</th>\n",
       "      <th>zyl</th>\n",
       "      <th>zyt5bpe</th>\n",
       "      <th>zzetat</th>\n",
       "      <th>zzgrrgf</th>\n",
       "      <th>zzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4061 rows × 11264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000  008relo  00fvvdw  00igyua  01  01tdt1o  02  03  04  05  ...  \\\n",
       "0       0        0        0        0   0        0   0   0   0   0  ...   \n",
       "1       0        0        0        0   0        0   0   0   0   0  ...   \n",
       "2       0        0        0        0   0        0   0   0   0   0  ...   \n",
       "3       0        0        0        0   0        0   0   0   0   0  ...   \n",
       "4       0        0        0        0   0        0   0   0   0   0  ...   \n",
       "...   ...      ...      ...      ...  ..      ...  ..  ..  ..  ..  ...   \n",
       "4056    0        0        0        0   0        0   0   0   0   0  ...   \n",
       "4057    0        0        0        0   0        0   0   0   0   0  ...   \n",
       "4058    0        0        0        0   0        0   0   0   0   0  ...   \n",
       "4059    0        0        0        0   0        0   0   0   0   0  ...   \n",
       "4060    0        0        0        0   0        0   0   0   0   0  ...   \n",
       "\n",
       "      zwwtu7  zxodiqo  zy53fec  zy7u11  zyam2xi  zyl  zyt5bpe  zzetat  \\\n",
       "0          0        0        0       0        0    0        0       0   \n",
       "1          0        0        0       0        0    0        0       0   \n",
       "2          0        0        0       0        0    0        0       0   \n",
       "3          0        0        0       0        0    0        0       0   \n",
       "4          0        0        0       0        0    0        0       0   \n",
       "...      ...      ...      ...     ...      ...  ...      ...     ...   \n",
       "4056       0        0        0       0        0    0        0       0   \n",
       "4057       0        0        0       0        0    0        0       0   \n",
       "4058       0        0        0       0        0    0        0       0   \n",
       "4059       0        0        0       0        0    0        0       0   \n",
       "4060       0        0        0       0        0    0        0       0   \n",
       "\n",
       "      zzgrrgf  zzzzz  \n",
       "0           0      0  \n",
       "1           0      0  \n",
       "2           0      0  \n",
       "3           0      0  \n",
       "4           0      0  \n",
       "...       ...    ...  \n",
       "4056        0      0  \n",
       "4057        0      0  \n",
       "4058        0      0  \n",
       "4059        0      0  \n",
       "4060        0      0  \n",
       "\n",
       "[4061 rows x 11264 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate \"bag of words\" pandas DataFrame\n",
    "bag_of_words_dataframe = get_bag_of_words_dataframe(tweets_list)\n",
    "\n",
    "# display \"bag of words\" pandas DataFrame\n",
    "bag_of_words_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the tweets summary DataFrame..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Tweets</th>\n",
       "      <th># Total Tokens</th>\n",
       "      <th># Unique Tokens</th>\n",
       "      <th>Avg. Tokens Per Tweet</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4061</td>\n",
       "      <td>441036</td>\n",
       "      <td>11264</td>\n",
       "      <td>108.602807</td>\n",
       "      <td>CNN Health Tweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # Tweets  # Total Tokens  # Unique Tokens  Avg. Tokens Per Tweet  \\\n",
       "0      4061          441036            11264             108.602807   \n",
       "\n",
       "         Description  \n",
       "0  CNN Health Tweets  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate \"bag of words\" pandas DataFrame\n",
    "tweets_summary_dataframe = get_tweets_summary_dataframe(tweets_list)\n",
    "\n",
    "tweets_summary_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance measure #1: Eucliean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 6.4807407 , 6.55743852, ..., 6.        , 6.164414  ,\n",
       "        5.65685425],\n",
       "       [6.4807407 , 0.        , 6.40312424, ..., 5.65685425, 5.83095189,\n",
       "        5.29150262],\n",
       "       [6.55743852, 6.40312424, 0.        , ..., 5.74456265, 5.56776436,\n",
       "        5.38516481],\n",
       "       ...,\n",
       "       [6.        , 5.65685425, 5.74456265, ..., 0.        , 4.47213595,\n",
       "        3.74165739],\n",
       "       [6.164414  , 5.83095189, 5.56776436, ..., 4.47213595, 0.        ,\n",
       "        4.        ],\n",
       "       [5.65685425, 5.29150262, 5.38516481, ..., 3.74165739, 4.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_matrix = get_bag_of_words_matrix(tweets_list)\n",
    "\n",
    "bag_of_words_matrix_ed = get_euclidean_distance(bag_of_words_matrix)\n",
    "\n",
    "bag_of_words_matrix_ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance measure #2: Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.22222222, 0.21821789, ..., 0.1067521 , 0.0993808 ,\n",
       "        0.12830006],\n",
       "       [0.22222222, 1.        , 0.25458754, ..., 0.21350421, 0.1987616 ,\n",
       "        0.25660012],\n",
       "       [0.21821789, 0.25458754, 1.        , ..., 0.20965697, 0.29277002,\n",
       "        0.25197632],\n",
       "       ...,\n",
       "       [0.1067521 , 0.21350421, 0.20965697, ..., 1.        , 0.28644595,\n",
       "        0.36980013],\n",
       "       [0.0993808 , 0.1987616 , 0.29277002, ..., 0.28644595, 1.        ,\n",
       "        0.34426519],\n",
       "       [0.12830006, 0.25660012, 0.25197632, ..., 0.36980013, 0.34426519,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_matrix = get_bag_of_words_matrix(tweets_list)\n",
    "\n",
    "bag_of_words_matrix_cs = get_cosine_similarity(bag_of_words_matrix)\n",
    "\n",
    "bag_of_words_matrix_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using KMeans..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First cluster with euclidean distance as the distance measure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\charl\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([14, 16, 17, ...,  2, 17, 18])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = get_bag_of_words_matrix(tweets_list)\n",
    "\n",
    "kmeans = KMeans(n_clusters = 20, random_state = 0)\n",
    "kmeans.fit(bow)\n",
    "\n",
    "labels = kmeans.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Starting soon: Allergies getting you down? Join our #CNNAllergies Twitter chat at 1:30pm EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>TODAY: Join our #CNNAllergies Twitter chat at 1:30pm EST with @AllergyReliefNY and ask all of your allergy questions http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>TODAY: Allergies getting you down? Join our #CNNAllergies Twitter chat at 1:30pm EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Questions about #allergies? Ask us using hashtag #CNNAllergies. Chat is TOMORROW at 1:30pm EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Allergies getting you down? Join our #CNNAllergies chat TOMORROW at 1:30pm EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>Join our #CNNAllergies chat TOMORROW at 1:30pm EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>Learn about #allergies tomorrow! Send us your questions before our #CNNAllergies chat on 4/23 @ 1:30 pm ET http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>What can you do to get allergy relief? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Allergies getting you down? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>Allergies getting you down? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>What can you do to get allergy relief? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>What do you want to know about #allergies? Send us your questions before our #CNNAllergies chat on 4/23 @ 1:30 pm ET http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>What do you want to know about #allergies? Send us your questions before our #CNNAllergies chat on 4/23 @ 1:30 pm ET http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>What can you do to get allergy relief? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Allergies getting you down? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>What can you do to get allergy relief? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>@MelEdits Thanks for those #CNNAllergies Qs! We hope you'll join us for the chat on 4/23 at 1:30 p.m EST</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>What do you want to know about #allergies? Send us your questions before our #CNNAllergies chat on 4/23 @ 1:30 pm ET http://on.fb.me/1k9W1v8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>Join us &amp;amp; @namicommunicate @DrashmanCNN @KellyWallaceTV tmw for a chat on raising kids w/ mental illness: http://on.fb.me/1d5gkEa #CNNParents</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 tweets  \\\n",
       "999          Starting soon: Allergies getting you down? Join our #CNNAllergies Twitter chat at 1:30pm EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1003       TODAY: Join our #CNNAllergies Twitter chat at 1:30pm EST with @AllergyReliefNY and ask all of your allergy questions http://on.fb.me/1k9W1v8   \n",
       "1005                 TODAY: Allergies getting you down? Join our #CNNAllergies Twitter chat at 1:30pm EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1009       Questions about #allergies? Ask us using hashtag #CNNAllergies. Chat is TOMORROW at 1:30pm EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1011                       Allergies getting you down? Join our #CNNAllergies chat TOMORROW at 1:30pm EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1013                                                   Join our #CNNAllergies chat TOMORROW at 1:30pm EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1016                 Learn about #allergies tomorrow! Send us your questions before our #CNNAllergies chat on 4/23 @ 1:30 pm ET http://on.fb.me/1k9W1v8   \n",
       "1023          What can you do to get allergy relief? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1026                     Allergies getting you down? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1027                     Allergies getting you down? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1029          What can you do to get allergy relief? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1033       What do you want to know about #allergies? Send us your questions before our #CNNAllergies chat on 4/23 @ 1:30 pm ET http://on.fb.me/1k9W1v8   \n",
       "1035       What do you want to know about #allergies? Send us your questions before our #CNNAllergies chat on 4/23 @ 1:30 pm ET http://on.fb.me/1k9W1v8   \n",
       "1037          What can you do to get allergy relief? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1041                     Allergies getting you down? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1044          What can you do to get allergy relief? Join our #CNNAllergies chat on 4/23 at 1:30 p.m. EST with @AllergyReliefNY http://on.fb.me/1k9W1v8   \n",
       "1064                                           @MelEdits Thanks for those #CNNAllergies Qs! We hope you'll join us for the chat on 4/23 at 1:30 p.m EST   \n",
       "1073       What do you want to know about #allergies? Send us your questions before our #CNNAllergies chat on 4/23 @ 1:30 pm ET http://on.fb.me/1k9W1v8   \n",
       "1696  Join us &amp; @namicommunicate @DrashmanCNN @KellyWallaceTV tmw for a chat on raising kids w/ mental illness: http://on.fb.me/1d5gkEa #CNNParents   \n",
       "\n",
       "      label  \n",
       "999       1  \n",
       "1003      1  \n",
       "1005      1  \n",
       "1009      1  \n",
       "1011      1  \n",
       "1013      1  \n",
       "1016      1  \n",
       "1023      1  \n",
       "1026      1  \n",
       "1027      1  \n",
       "1029      1  \n",
       "1033      1  \n",
       "1035      1  \n",
       "1037      1  \n",
       "1041      1  \n",
       "1044      1  \n",
       "1064      1  \n",
       "1073      1  \n",
       "1696      1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'tweets': tweets_list,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First cluster with cosine similarity as the distance measure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\charl\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21,  6,  2, ..., 15, 28, 15])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = get_bag_of_words_matrix(tweets_list)\n",
    "normalized_bow = normalize(bow, norm='l2', axis=1)\n",
    "\n",
    "kmeans = KMeans(n_clusters = 30, random_state = 0)\n",
    "kmeans.fit(normalized_bow)\n",
    "\n",
    "labels = kmeans.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>. @Schwarzenegger trained 1 hr/day to be in shape for @EscapePlanMovie. His tips for working out on the road http://www.cnn.com/2013/10/18/health/arnold-schwarzenegger-travel-workout/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>Mentally ill #Latinos struggle to get help http://www.cnn.com/2013/10/09/health/latino-mental-health-disparities/index.html #LATISM @UN @WHO #WMHD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>Fat-burning supplement pulled from shelves after it's linked to liver failure, acute hepatitis http://www.cnn.com/2013/10/09/health/oxyelite-pro-liver-damage/index.html @HIgov_Health</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>#Latinos struggle to find help for #mental #health issues http://www.cnn.com/2013/10/09/health/latino-mental-health-disparities/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>Were you or your child supposed to start a clinical trial that may be delayed b/c of the #shutdown? Let us know http://www.cnn.com/2013/10/01/health/shutdown-nih-clinical-trials/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>Why #beer is good for your health http://www.cnn.com/2013/09/30/health/beer-good-health/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>It's news Homer Simpson will love: Beer, it's good for you. The health benefits of a good cold one:  http://www.cnn.com/2013/09/30/health/beer-good-health/?hpt=he_t3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>An ireporter lost 158 pounds in part by leaving a photographic reminder of just how heavy he was everywhere he looked http://www.cnn.com/2013/09/30/health/irpt-weight-loss-trotter/index.html?hpt=he_c1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>Check out these 15 superfoods for fall! http://www.cnn.com/2013/09/27/health/gallery/best-fall-superfoods/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>Hip hop health, a fun &amp;amp; effective health program that helps kids lose weight &amp;amp; helped one kid save his grandma's life http://www.cnn.com/2013/09/27/health/hip-hop-health/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>#Obamacare 101: if you plan to shop in the marketplaces here's everything you need to know http://www.cnn.com/2013/09/26/health/obamacare-open-enrollment/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>It's open enrollment time. These are health insurance terms most people don't know. What you don't know can cost you http://www.cnn.com/2013/09/26/health/obamacare-glossary/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>5 questions you should be sure to ask before going under the knife: http://www.cnn.com/2013/09/25/health/surgery-questions/index.html?hpt=he_c1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>Interactive map of health care options under #Obamacare: http://www.cnn.com/interactive/2013/09/health/map-obamacare/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>Drinking really does reduce stress... kind of. http://www.cnn.com/2013/09/24/health/drinking-reduces-stress-upwave/index.html?hpt=he_c1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>Regina Lopez went from 224 to 127lbs find out how an App &amp;amp; stairs helped http://www.cnn.com/2013/09/23/health/weight-loss-regina-lopez/index.html?hpt=he_c1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>The 'next outbreak may be just a plane ride away' @CDCgov Dr. Frieden says of our vulnerability to disease http://www.cnn.com/2013/09/20/health/disease-outbreak-risk-frieden/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>FRUSTRATION doesn't even begin to cover what this #Alzheimers caregiver feels every day http://www.cnn.com/2013/09/19/health/world-alzheimers-report-caregivers/index.html @alzassociation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>\"Ray Donovan\" star @DizMihok used to hide his #Tourettes from casting directors. Now he embraces it http://www.cnn.com/2013/09/19/health/dash-mihok-tourette-syndrome/index.html @JaysChallenge</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>Food reached its expiration date? Don't toss it just yet http://www.cnn.com/2013/09/19/health/sell-by-dates-waste-food/index.html via @TIMEHealthland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>The back #pain most surgeons won't find http://www.cnn.com/2013/09/18/health/back-pain-misdiagnosis-shamie/index.html  @uclaspine @UCLAHealth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>10 apps that make managing your #healthcare a breeze http://www.cnn.com/2013/09/17/health/gallery/personal-healthcare-apps/index.html #ourmobilesociety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Dear @upwave, Thanks for answering the question we've always wanted to ask: How much #sex is considered #exercise? http://www.cnn.com/2013/09/17/health/sex-calorie-burn-upwave/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>Food #allergies cost families big bucks -- about  $4,184 per child, per year http://www.cnn.com/2013/09/17/health/food-allergies-cost-time/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>18 untreatable superbugs: @CDCgov warns of 'post-antibiotic era' http://www.cnn.com/2013/09/16/health/antibiotic-resistant-infections-cdc/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>Bullying is an \"international public health problem,\" experts say. This boy has asked Santa to fix it http://www.cnn.com/2013/09/16/us/bullying-santa-letter-ireport/index.html @cnnireport</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>Self-control: The brain's untapped power http://www.cnn.com/2013/09/14/health/self-control-brain/index.html #getfit #weightloss @lizlandau</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>His dad couldn't smile b/c of Bell's palsy, so Harrison decided he wouldn't either. A beautiful story @cnnireport http://www.cnn.com/2013/09/13/health/bells-palsy-essay-irpt/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>RT @MeaslesRubella: #US measles cases in 2013 may be most in 17 years - http://edition.cnn.com/2013/09/12/health/worst-measles-year/index.html?hpt=hp_t2&amp;utm_source=buffer&amp;utm_campaign=Buffer&amp;utm_content=bufferb02d0&amp;utm_medium=twitter via @cnnhealth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>We're on track to have the worst year for #measles in more than a decade, @CDCgov says http://www.cnn.com/2013/09/12/health/worst-measles-year/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>More than 1,100 have #cancer after #September11 http://www.cnn.com/2013/09/11/health/911-cancer-treatment/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>Why I workout when the kids go to bed http://www.cnn.com/2013/09/10/health/workout-kids-parenting-upwave/index.html via @upwave #getfit #cnnparents @CNNLiving</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>Think cheating will make you feel guilty? Think again http://www.cnn.com/2013/09/10/health/why-we-cheat-time/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>'Eden is here to save lives': Parents push for standardized screening of #Jewish genetic diseases http://www.cnn.com/2013/09/10/health/jewish-genetic-diseases-screening/index.html @MyJScreen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>He lost 245 pounds using the 3 \"P's\" http://www.cnn.com/2013/09/09/health/weight-loss-marlon-gibson/index.html #getfit #weightloss #fitspiration @jechristensen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>. @drsanjaygupta: \"I now know the look of eyes that have not seen food for too long. They can look at nothing else\" http://www.cnn.com/2013/09/08/health/gupta-child-refugees-syria-lebanon/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>75 illnesses, 3 deaths may be tied to synthetic #marijuana in Colorado http://www.cnn.com/2013/09/06/health/synthetic-marijuana-denver/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>The #cancer @ValerieHarper really has http://www.cnn.com/2013/09/05/health/valerie-harper-cancer/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>This couple was \"pissed\" to be pregnant with twins. Find out why: http://www.cnn.com/2013/09/04/health/babble-twins-ivf-multiples/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>Do your friends hurt or help your #health? Maybe it's time to find friends who will support an active lifestyle http://www.cnn.com/2013/09/04/health/easy-weight-loss-tips/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>Save 'em and share 'em: 11 simple weight loss tips, via @jdwilson2 http://www.cnn.com/2013/09/04/health/easy-weight-loss-tips/index.html #getfit @ObesityAction @djblatner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>Good news! @NIAIDNews director says there's a better #flu #vaccine on the horizon  http://www.cnn.com/2013/09/03/health/better-flu-vaccine-fauci/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>Hm… maybe a morning romp would start the week off right. Thanks @upwave! http://www.cnn.com/2013/09/03/health/sex-health-benefits-upwave/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>Would you feel comfortable sharing your medical problems in front of your doctor AND strangers? sharing doctor visits http://www.cnn.com/2013/08/09/health/shared-doctors-appts-time/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>Dancing w/ the Stars doesn't premiere for a few wks. Get ur fix with these #health tips from host @brookeburke http://www.cnn.com/2013/08/06/health/brooke-burke-charvet-secrets/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>Some #cancer may be more boogey-man-in-the-closet scary than serial killer scary http://www.cnn.com/2013/07/30/health/cancer-overdiagnosis-overtreatment/index.html @NCIMedia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>Animal toxins may be hazardous, but scientists are hoping to turn them into powerful medications. #health http://edition.cnn.com/2013/07/18/health/toxin-treatments-time/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                        tweets  \\\n",
       "1907                                                         . @Schwarzenegger trained 1 hr/day to be in shape for @EscapePlanMovie. His tips for working out on the road http://www.cnn.com/2013/10/18/health/arnold-schwarzenegger-travel-workout/index.html   \n",
       "1936                                                                                                        Mentally ill #Latinos struggle to get help http://www.cnn.com/2013/10/09/health/latino-mental-health-disparities/index.html #LATISM @UN @WHO #WMHD   \n",
       "1945                                                                    Fat-burning supplement pulled from shelves after it's linked to liver failure, acute hepatitis http://www.cnn.com/2013/10/09/health/oxyelite-pro-liver-damage/index.html @HIgov_Health   \n",
       "1946                                                                                                                #Latinos struggle to find help for #mental #health issues http://www.cnn.com/2013/10/09/health/latino-mental-health-disparities/index.html   \n",
       "1969                                                              Were you or your child supposed to start a clinical trial that may be delayed b/c of the #shutdown? Let us know http://www.cnn.com/2013/10/01/health/shutdown-nih-clinical-trials/index.html   \n",
       "1975                                                                                                                                                                  Why #beer is good for your health http://www.cnn.com/2013/09/30/health/beer-good-health/   \n",
       "1976                                                                                     It's news Homer Simpson will love: Beer, it's good for you. The health benefits of a good cold one:  http://www.cnn.com/2013/09/30/health/beer-good-health/?hpt=he_t3   \n",
       "1977                                                  An ireporter lost 158 pounds in part by leaving a photographic reminder of just how heavy he was everywhere he looked http://www.cnn.com/2013/09/30/health/irpt-weight-loss-trotter/index.html?hpt=he_c1   \n",
       "1978                                                                                                                                      Check out these 15 superfoods for fall! http://www.cnn.com/2013/09/27/health/gallery/best-fall-superfoods/index.html   \n",
       "1979                                                              Hip hop health, a fun &amp; effective health program that helps kids lose weight &amp; helped one kid save his grandma's life http://www.cnn.com/2013/09/27/health/hip-hop-health/index.html   \n",
       "1980                                                                                      #Obamacare 101: if you plan to shop in the marketplaces here's everything you need to know http://www.cnn.com/2013/09/26/health/obamacare-open-enrollment/index.html   \n",
       "1981                                                                   It's open enrollment time. These are health insurance terms most people don't know. What you don't know can cost you http://www.cnn.com/2013/09/26/health/obamacare-glossary/index.html   \n",
       "1983                                                                                                           5 questions you should be sure to ask before going under the knife: http://www.cnn.com/2013/09/25/health/surgery-questions/index.html?hpt=he_c1   \n",
       "1984                                                                                                                           Interactive map of health care options under #Obamacare: http://www.cnn.com/interactive/2013/09/health/map-obamacare/index.html   \n",
       "1986                                                                                                                   Drinking really does reduce stress... kind of. http://www.cnn.com/2013/09/24/health/drinking-reduces-stress-upwave/index.html?hpt=he_c1   \n",
       "1988                                                                                           Regina Lopez went from 224 to 127lbs find out how an App &amp; stairs helped http://www.cnn.com/2013/09/23/health/weight-loss-regina-lopez/index.html?hpt=he_c1   \n",
       "1989                                                                  The 'next outbreak may be just a plane ride away' @CDCgov Dr. Frieden says of our vulnerability to disease http://www.cnn.com/2013/09/20/health/disease-outbreak-risk-frieden/index.html   \n",
       "1992                                                                FRUSTRATION doesn't even begin to cover what this #Alzheimers caregiver feels every day http://www.cnn.com/2013/09/19/health/world-alzheimers-report-caregivers/index.html @alzassociation   \n",
       "1993                                                           \"Ray Donovan\" star @DizMihok used to hide his #Tourettes from casting directors. Now he embraces it http://www.cnn.com/2013/09/19/health/dash-mihok-tourette-syndrome/index.html @JaysChallenge   \n",
       "1994                                                                                                     Food reached its expiration date? Don't toss it just yet http://www.cnn.com/2013/09/19/health/sell-by-dates-waste-food/index.html via @TIMEHealthland   \n",
       "1996                                                                                                             The back #pain most surgeons won't find http://www.cnn.com/2013/09/18/health/back-pain-misdiagnosis-shamie/index.html  @uclaspine @UCLAHealth   \n",
       "2000                                                                                                   10 apps that make managing your #healthcare a breeze http://www.cnn.com/2013/09/17/health/gallery/personal-healthcare-apps/index.html #ourmobilesociety   \n",
       "2001                                                                Dear @upwave, Thanks for answering the question we've always wanted to ask: How much #sex is considered #exercise? http://www.cnn.com/2013/09/17/health/sex-calorie-burn-upwave/index.html   \n",
       "2002                                                                                                     Food #allergies cost families big bucks -- about  $4,184 per child, per year http://www.cnn.com/2013/09/17/health/food-allergies-cost-time/index.html   \n",
       "2004                                                                                                      18 untreatable superbugs: @CDCgov warns of 'post-antibiotic era' http://www.cnn.com/2013/09/16/health/antibiotic-resistant-infections-cdc/index.html   \n",
       "2007                                                               Bullying is an \"international public health problem,\" experts say. This boy has asked Santa to fix it http://www.cnn.com/2013/09/16/us/bullying-santa-letter-ireport/index.html @cnnireport   \n",
       "2009                                                                                                                Self-control: The brain's untapped power http://www.cnn.com/2013/09/14/health/self-control-brain/index.html #getfit #weightloss @lizlandau   \n",
       "2010                                                                  His dad couldn't smile b/c of Bell's palsy, so Harrison decided he wouldn't either. A beautiful story @cnnireport http://www.cnn.com/2013/09/13/health/bells-palsy-essay-irpt/index.html   \n",
       "2015  RT @MeaslesRubella: #US measles cases in 2013 may be most in 17 years - http://edition.cnn.com/2013/09/12/health/worst-measles-year/index.html?hpt=hp_t2&utm_source=buffer&utm_campaign=Buffer&utm_content=bufferb02d0&utm_medium=twitter via @cnnhealth   \n",
       "2018                                                                                                 We're on track to have the worst year for #measles in more than a decade, @CDCgov says http://www.cnn.com/2013/09/12/health/worst-measles-year/index.html   \n",
       "2023                                                                                                                                      More than 1,100 have #cancer after #September11 http://www.cnn.com/2013/09/11/health/911-cancer-treatment/index.html   \n",
       "2025                                                                                            Why I workout when the kids go to bed http://www.cnn.com/2013/09/10/health/workout-kids-parenting-upwave/index.html via @upwave #getfit #cnnparents @CNNLiving   \n",
       "2026                                                                                                                                   Think cheating will make you feel guilty? Think again http://www.cnn.com/2013/09/10/health/why-we-cheat-time/index.html   \n",
       "2027                                                            'Eden is here to save lives': Parents push for standardized screening of #Jewish genetic diseases http://www.cnn.com/2013/09/10/health/jewish-genetic-diseases-screening/index.html @MyJScreen   \n",
       "2030                                                                                           He lost 245 pounds using the 3 \"P's\" http://www.cnn.com/2013/09/09/health/weight-loss-marlon-gibson/index.html #getfit #weightloss #fitspiration @jechristensen   \n",
       "2032                                                    . @drsanjaygupta: \"I now know the look of eyes that have not seen food for too long. They can look at nothing else\" http://www.cnn.com/2013/09/08/health/gupta-child-refugees-syria-lebanon/index.html   \n",
       "2034                                                                                                         75 illnesses, 3 deaths may be tied to synthetic #marijuana in Colorado http://www.cnn.com/2013/09/06/health/synthetic-marijuana-denver/index.html   \n",
       "2038                                                                                                                                               The #cancer @ValerieHarper really has http://www.cnn.com/2013/09/05/health/valerie-harper-cancer/index.html   \n",
       "2041                                                                                                              This couple was \"pissed\" to be pregnant with twins. Find out why: http://www.cnn.com/2013/09/04/health/babble-twins-ivf-multiples/index.html   \n",
       "2042                                                                     Do your friends hurt or help your #health? Maybe it's time to find friends who will support an active lifestyle http://www.cnn.com/2013/09/04/health/easy-weight-loss-tips/index.html   \n",
       "2043                                                                                Save 'em and share 'em: 11 simple weight loss tips, via @jdwilson2 http://www.cnn.com/2013/09/04/health/easy-weight-loss-tips/index.html #getfit @ObesityAction @djblatner   \n",
       "2047                                                                                               Good news! @NIAIDNews director says there's a better #flu #vaccine on the horizon  http://www.cnn.com/2013/09/03/health/better-flu-vaccine-fauci/index.html   \n",
       "2048                                                                                                       Hm… maybe a morning romp would start the week off right. Thanks @upwave! http://www.cnn.com/2013/09/03/health/sex-health-benefits-upwave/index.html   \n",
       "2126                                                           Would you feel comfortable sharing your medical problems in front of your doctor AND strangers? sharing doctor visits http://www.cnn.com/2013/08/09/health/shared-doctors-appts-time/index.html   \n",
       "2137                                                               Dancing w/ the Stars doesn't premiere for a few wks. Get ur fix with these #health tips from host @brookeburke http://www.cnn.com/2013/08/06/health/brooke-burke-charvet-secrets/index.html   \n",
       "2159                                                                             Some #cancer may be more boogey-man-in-the-closet scary than serial killer scary http://www.cnn.com/2013/07/30/health/cancer-overdiagnosis-overtreatment/index.html @NCIMedia   \n",
       "2201                                                                                 Animal toxins may be hazardous, but scientists are hoping to turn them into powerful medications. #health http://edition.cnn.com/2013/07/18/health/toxin-treatments-time/   \n",
       "\n",
       "      label  \n",
       "1907      0  \n",
       "1936      0  \n",
       "1945      0  \n",
       "1946      0  \n",
       "1969      0  \n",
       "1975      0  \n",
       "1976      0  \n",
       "1977      0  \n",
       "1978      0  \n",
       "1979      0  \n",
       "1980      0  \n",
       "1981      0  \n",
       "1983      0  \n",
       "1984      0  \n",
       "1986      0  \n",
       "1988      0  \n",
       "1989      0  \n",
       "1992      0  \n",
       "1993      0  \n",
       "1994      0  \n",
       "1996      0  \n",
       "2000      0  \n",
       "2001      0  \n",
       "2002      0  \n",
       "2004      0  \n",
       "2007      0  \n",
       "2009      0  \n",
       "2010      0  \n",
       "2015      0  \n",
       "2018      0  \n",
       "2023      0  \n",
       "2025      0  \n",
       "2026      0  \n",
       "2027      0  \n",
       "2030      0  \n",
       "2032      0  \n",
       "2034      0  \n",
       "2038      0  \n",
       "2041      0  \n",
       "2042      0  \n",
       "2043      0  \n",
       "2047      0  \n",
       "2048      0  \n",
       "2126      0  \n",
       "2137      0  \n",
       "2159      0  \n",
       "2201      0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'tweets': tweets_list,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "df[df['label'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using Hierarhical Clustering..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First cluster with euclidean distance as the distance measure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m bow \u001b[38;5;241m=\u001b[39m get_bag_of_words_matrix(tweets_list)\n\u001b[0;32m      2\u001b[0m normalized_bow \u001b[38;5;241m=\u001b[39m normalize(bow, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m clustering \u001b[38;5;241m=\u001b[39m AgglomerativeClustering()\u001b[38;5;241m.\u001b[39mfit(bow)\n\u001b[0;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m clustering\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m      7\u001b[0m labels\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:977\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    960\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the hierarchical clustering from features, or distance matrix.\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \n\u001b[0;32m    962\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;124;03m        Returns the fitted instance.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 977\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:883\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[0;32m    882\u001b[0m     _ensure_no_complex_data(array)\n\u001b[1;32m--> 883\u001b[0m     array \u001b[38;5;241m=\u001b[39m _ensure_sparse_format(\n\u001b[0;32m    884\u001b[0m         array,\n\u001b[0;32m    885\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m    886\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    887\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    888\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    889\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m    890\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    891\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    892\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:534\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    531\u001b[0m _check_large_sparse(spmatrix, accept_large_sparse)\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA sparse matrix was passed, but dense \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata is required. Use X.toarray() to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m     )\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accept_sparse, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accept_sparse) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "bow = get_bag_of_words_matrix(tweets_list)\n",
    "normalized_bow = normalize(bow, norm='l2', axis=1)\n",
    "\n",
    "clustering = AgglomerativeClustering.fit(bow)\n",
    "\n",
    "labels = clustering.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>Did you love the #CNN10 Better by Design? Be a part of our next  project: http://ireport.cnn.com/topics/1153052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>#Obamacare call center reps get password reset script by mistake http://on.cnn.com/15ruChD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>New deadly flu launched by live bird markets http://thechart.blogs.cnn.com/2013/08/21/new-deadly-flu-launched-by-live-bird-markets/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>More children being injured by toppling TVs http://thechart.blogs.cnn.com/2013/07/22/more-children-being-injured-by-toppling-tvs/ #kidshealth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>Meet DNA pioneer James Watson, our #LifesWork profile of the week, sponsored by @GeneralElectric http://at.cnn.com/zUvg0Wj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>Minority children with #autism less likely to be seen by specialists http://at.cnn.com/1siBFKA @autismspeaks @VahabzadehMD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>Baby's brain aneurysm halted -- by superglue http://at.cnn.com/LlZAYcI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>#Cancer: By the numbers http://at.cnn.com/3fxq5Wp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>Health care workers sickened by new virus http://at.cnn.com/xsI7X6v</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>Check out this cool infographic! #Allergies: By the numbers http://at.cnn.com/y1A7Z4z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>Indoor tanning under scrutiny by FDA, CDC http://at.cnn.com/g2VLWGC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>MT @DanielleCNN: Using indoor tanning beds before age 35 ups your risk of skin cancer by 75%. Teens are top concern http://on.cnn.com/15ApskV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>Premature twin saved by hug http://at.cnn.com/52eLGHc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>Beautiful piece by @jdsutter on why #RunForBoston matters http://at.cnn.com/ptzMKd4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>Cool alert! Bionic hands controlled by iPhone app http://at.cnn.com/UxDbWcI (via @DanielleCNN)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>Hey @GoRedForWomen @TheHeartTruth @WomansDay! Pls share this #heart healthy article by Allison Janney http://at.cnn.com/1JuMFUo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>So proud! Our @CNNFitNation team kicked off their training by conquering a mountain http://at.cnn.com/YhSQRLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>Caregiver lives rerouted yet enriched by aging parents http://at.cnn.com/dKBjvPs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>Women who give up smoking extend lives by 10 years http://at.cnn.com/EagoH8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>Is psychiatry committing 'professional suicide' by not addressing their drug industry relationship? http://at.cnn.com/5rGwPR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>Money backs up vow to eradicate polio by 2015 http://at.cnn.com/cef1zJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>Man tormented by sounds of his own body http://at.cnn.com/VNFTb8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>Watch: Family strained by surrogacy http://at.cnn.com/2SAAqB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>Why you really should get 'Fit By 40' http://at.cnn.com/pK7AjUC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweets  \\\n",
       "583                                 Did you love the #CNN10 Better by Design? Be a part of our next  project: http://ireport.cnn.com/topics/1153052   \n",
       "1938                                                     #Obamacare call center reps get password reset script by mistake http://on.cnn.com/15ruChD   \n",
       "2089            New deadly flu launched by live bird markets http://thechart.blogs.cnn.com/2013/08/21/new-deadly-flu-launched-by-live-bird-markets/   \n",
       "2190  More children being injured by toppling TVs http://thechart.blogs.cnn.com/2013/07/22/more-children-being-injured-by-toppling-tvs/ #kidshealth   \n",
       "2304                     Meet DNA pioneer James Watson, our #LifesWork profile of the week, sponsored by @GeneralElectric http://at.cnn.com/zUvg0Wj   \n",
       "2402                     Minority children with #autism less likely to be seen by specialists http://at.cnn.com/1siBFKA @autismspeaks @VahabzadehMD   \n",
       "2434                                                                         Baby's brain aneurysm halted -- by superglue http://at.cnn.com/LlZAYcI   \n",
       "2492                                                                                              #Cancer: By the numbers http://at.cnn.com/3fxq5Wp   \n",
       "2616                                                                            Health care workers sickened by new virus http://at.cnn.com/xsI7X6v   \n",
       "2651                                                          Check out this cool infographic! #Allergies: By the numbers http://at.cnn.com/y1A7Z4z   \n",
       "2680                                                                            Indoor tanning under scrutiny by FDA, CDC http://at.cnn.com/g2VLWGC   \n",
       "2688  MT @DanielleCNN: Using indoor tanning beds before age 35 ups your risk of skin cancer by 75%. Teens are top concern http://on.cnn.com/15ApskV   \n",
       "2749                                                                                          Premature twin saved by hug http://at.cnn.com/52eLGHc   \n",
       "2756                                                            Beautiful piece by @jdsutter on why #RunForBoston matters http://at.cnn.com/ptzMKd4   \n",
       "2808                                                 Cool alert! Bionic hands controlled by iPhone app http://at.cnn.com/UxDbWcI (via @DanielleCNN)   \n",
       "3169                Hey @GoRedForWomen @TheHeartTruth @WomansDay! Pls share this #heart healthy article by Allison Janney http://at.cnn.com/1JuMFUo   \n",
       "3198                                  So proud! Our @CNNFitNation team kicked off their training by conquering a mountain http://at.cnn.com/YhSQRLE   \n",
       "3476                                                               Caregiver lives rerouted yet enriched by aging parents http://at.cnn.com/dKBjvPs   \n",
       "3685                                                                    Women who give up smoking extend lives by 10 years http://at.cnn.com/EagoH8   \n",
       "3782                   Is psychiatry committing 'professional suicide' by not addressing their drug industry relationship? http://at.cnn.com/5rGwPR   \n",
       "3839                                                                         Money backs up vow to eradicate polio by 2015 http://at.cnn.com/cef1zJ   \n",
       "3893                                                                               Man tormented by sounds of his own body http://at.cnn.com/VNFTb8   \n",
       "3955                                                                                   Watch: Family strained by surrogacy http://at.cnn.com/2SAAqB   \n",
       "4010                                                                                Why you really should get 'Fit By 40' http://at.cnn.com/pK7AjUC   \n",
       "\n",
       "      label  \n",
       "583       1  \n",
       "1938      1  \n",
       "2089      1  \n",
       "2190      1  \n",
       "2304      1  \n",
       "2402      1  \n",
       "2434      1  \n",
       "2492      1  \n",
       "2616      1  \n",
       "2651      1  \n",
       "2680      1  \n",
       "2688      1  \n",
       "2749      1  \n",
       "2756      1  \n",
       "2808      1  \n",
       "3169      1  \n",
       "3198      1  \n",
       "3476      1  \n",
       "3685      1  \n",
       "3782      1  \n",
       "3839      1  \n",
       "3893      1  \n",
       "3955      1  \n",
       "4010      1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'tweets': tweets_list,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First cluster with cosine similarity as the distance measure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'csr_matrix' object has no attribute '_validate_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m bow \u001b[38;5;241m=\u001b[39m get_bag_of_words_matrix(tweets_list)\n\u001b[0;32m      2\u001b[0m normalized_bow \u001b[38;5;241m=\u001b[39m normalize(bow, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m clustering \u001b[38;5;241m=\u001b[39m AgglomerativeClustering\u001b[38;5;241m.\u001b[39mfit(normalized_bow)\n\u001b[0;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m clustering\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m      7\u001b[0m labels\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1144\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1140\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1141\u001b[0m )\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'csr_matrix' object has no attribute '_validate_params'"
     ]
    }
   ],
   "source": [
    "bow = get_bag_of_words_matrix(tweets_list)\n",
    "normalized_bow = normalize(bow, norm='l2', axis=1)\n",
    "\n",
    "clustering = AgglomerativeClustering.fit(normalized_bow)\n",
    "\n",
    "labels = clustering.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweets, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'tweets': tweets_list,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using DBSCAN..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First cluster with euclidean distance as the distance measure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1, 10], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = get_bag_of_words_matrix(tweets_list)\n",
    "\n",
    "cluster = DBSCAN(eps=3, min_samples=2).fit(bow)\n",
    "\n",
    "labels = cluster.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>#StrokeChat #WorldStrokeDay http://pbs.twimg.com/media/B1IVu2QCAAAM8or.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Are you at risk? Join us for a #WorldStrokeDay #StrokeChat w/ @American_Stroke at 1 p.m. ET http://pbs.twimg.com/media/B1G_rDaCAAANet9.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Join us for a #WorldStrokeDay #StrokeChat w/ @American_Stroke at 1 p.m. ET http://pbs.twimg.com/media/B1G_aLSCAAAeyBU.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>RT @DarianMurray: @cnnhealth oatmeal. Raisins, walnuts. http://pbs.twimg.com/media/BpNETvqIQAAWzsn.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>RT @DDworkouts: @cnnhealth granola, yogurt, strawberries. Fancy. http://pbs.twimg.com/media/BpNRZhfCYAAc1xT.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>RT @UMN_Health: @cnnhealth @WilliamCNN We do, too! http://pbs.twimg.com/media/BjqbzykCEAAU7Sc.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>RT @MMGHealth: @cnnhealth @WilliamCNN We hear you! http://pbs.twimg.com/media/BjqOwO2CAAA4Mtx.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>Mmmm! RT @AtarheHoover: @cnnhealth http://pbs.twimg.com/media/BjkodIgCYAEghBa.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>RT @apelsinkaX: @cnnhealth http://pbs.twimg.com/media/BjkiAskIYAA4r7G.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>RT @Taversha: @cnnhealth A cup ring of pollen! http://pbs.twimg.com/media/BHlpN0cCQAE8Ez2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                          tweets  \\\n",
       "197                                                                   #StrokeChat #WorldStrokeDay http://pbs.twimg.com/media/B1IVu2QCAAAM8or.jpg   \n",
       "203   Are you at risk? Join us for a #WorldStrokeDay #StrokeChat w/ @American_Stroke at 1 p.m. ET http://pbs.twimg.com/media/B1G_rDaCAAANet9.jpg   \n",
       "204                    Join us for a #WorldStrokeDay #StrokeChat w/ @American_Stroke at 1 p.m. ET http://pbs.twimg.com/media/B1G_aLSCAAAeyBU.jpg   \n",
       "777                                       RT @DarianMurray: @cnnhealth oatmeal. Raisins, walnuts. http://pbs.twimg.com/media/BpNETvqIQAAWzsn.jpg   \n",
       "778                              RT @DDworkouts: @cnnhealth granola, yogurt, strawberries. Fancy. http://pbs.twimg.com/media/BpNRZhfCYAAc1xT.jpg   \n",
       "1175                                           RT @UMN_Health: @cnnhealth @WilliamCNN We do, too! http://pbs.twimg.com/media/BjqbzykCEAAU7Sc.jpg   \n",
       "1176                                           RT @MMGHealth: @cnnhealth @WilliamCNN We hear you! http://pbs.twimg.com/media/BjqOwO2CAAA4Mtx.jpg   \n",
       "1185                                                           Mmmm! RT @AtarheHoover: @cnnhealth http://pbs.twimg.com/media/BjkodIgCYAEghBa.jpg   \n",
       "1186                                                                   RT @apelsinkaX: @cnnhealth http://pbs.twimg.com/media/BjkiAskIYAA4r7G.jpg   \n",
       "2851                                               RT @Taversha: @cnnhealth A cup ring of pollen! http://pbs.twimg.com/media/BHlpN0cCQAE8Ez2.jpg   \n",
       "\n",
       "      label  \n",
       "197       1  \n",
       "203       1  \n",
       "204       1  \n",
       "777       1  \n",
       "778       1  \n",
       "1175      1  \n",
       "1176      1  \n",
       "1185      1  \n",
       "1186      1  \n",
       "2851      1  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'tweets': tweets_list,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First cluster with cosine similarity as the distance measure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = get_bag_of_words_matrix(tweets_list)\n",
    "normalized_bow = normalize(bow, norm='l2', axis=1)\n",
    "\n",
    "cluster = DBSCAN(eps=3, min_samples=2).fit(normalized_bow)\n",
    "\n",
    "labels = cluster.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweets, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'tweets': tweets_list,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using EM Clustering..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First cluster with euclidean distance as the distance measure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(left, right)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:128\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     result \u001b[38;5;241m=\u001b[39m _evaluate_standard(op, op_str, a, b)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m bow \u001b[38;5;241m=\u001b[39m get_bag_of_words_matrix(tweets_list)\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m-\u001b[39m get_bag_of_words_dataframe(tweets_list)\n\u001b[0;32m      4\u001b[0m cluster \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      5\u001b[0m cluster\u001b[38;5;241m.\u001b[39mfit(bow)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arith_method(other, operator\u001b[38;5;241m.\u001b[39msub)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:7450\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   7449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mshould_reindex_frame_op(\u001b[38;5;28mself\u001b[39m, other, op, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 7450\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mframe_arith_method_with_reindex(\u001b[38;5;28mself\u001b[39m, other, op)\n\u001b[0;32m   7452\u001b[0m     axis: Literal[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[0;32m   7453\u001b[0m     other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\__init__.py:390\u001b[0m, in \u001b[0;36mframe_arith_method_with_reindex\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    388\u001b[0m new_left \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39miloc[:, lcols]\n\u001b[0;32m    389\u001b[0m new_right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39miloc[:, rcols]\n\u001b[1;32m--> 390\u001b[0m result \u001b[38;5;241m=\u001b[39m op(new_left, new_right)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Do the join on the columns instead of using align_method_FRAME\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m#  to avoid constructing two potentially large/sparse DataFrames\u001b[39;00m\n\u001b[0;32m    394\u001b[0m join_columns, _, _ \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    395\u001b[0m     right\u001b[38;5;241m.\u001b[39mcolumns, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_indexers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    396\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arith_method(other, operator\u001b[38;5;241m.\u001b[39msub)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:7457\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7453\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[0;32m   7455\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_FRAME(\u001b[38;5;28mself\u001b[39m, other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 7457\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   7458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:7496\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[1;34m(self, right, func, axis)\u001b[0m\n\u001b[0;32m   7490\u001b[0m     \u001b[38;5;66;03m# TODO: The previous assertion `assert right._indexed_same(self)`\u001b[39;00m\n\u001b[0;32m   7491\u001b[0m     \u001b[38;5;66;03m#  fails in cases with empty columns reached via\u001b[39;00m\n\u001b[0;32m   7492\u001b[0m     \u001b[38;5;66;03m#  _frame_arith_method_with_reindex\u001b[39;00m\n\u001b[0;32m   7493\u001b[0m \n\u001b[0;32m   7494\u001b[0m     \u001b[38;5;66;03m# TODO operate_blockwise expects a manager of the same type\u001b[39;00m\n\u001b[0;32m   7495\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 7496\u001b[0m         bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39moperate_blockwise(\n\u001b[0;32m   7497\u001b[0m             \u001b[38;5;66;03m# error: Argument 1 to \"operate_blockwise\" of \"ArrayManager\" has\u001b[39;00m\n\u001b[0;32m   7498\u001b[0m             \u001b[38;5;66;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;00m\n\u001b[0;32m   7499\u001b[0m             \u001b[38;5;66;03m# \"ArrayManager\"\u001b[39;00m\n\u001b[0;32m   7500\u001b[0m             \u001b[38;5;66;03m# error: Argument 1 to \"operate_blockwise\" of \"BlockManager\" has\u001b[39;00m\n\u001b[0;32m   7501\u001b[0m             \u001b[38;5;66;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;00m\n\u001b[0;32m   7502\u001b[0m             \u001b[38;5;66;03m# \"BlockManager\"\u001b[39;00m\n\u001b[0;32m   7503\u001b[0m             right\u001b[38;5;241m.\u001b[39m_mgr,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   7504\u001b[0m             array_op,\n\u001b[0;32m   7505\u001b[0m         )\n\u001b[0;32m   7506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(bm)\n\u001b[0;32m   7508\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, Series) \u001b[38;5;129;01mand\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   7509\u001b[0m     \u001b[38;5;66;03m# axis=1 means we want to operate row-by-row\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1545\u001b[0m, in \u001b[0;36mBlockManager.operate_blockwise\u001b[1;34m(self, other, array_op)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moperate_blockwise\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: BlockManager, array_op) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BlockManager:\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;124;03m    Apply array_op blockwise with another (aligned) BlockManager.\u001b[39;00m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m operate_blockwise(\u001b[38;5;28mself\u001b[39m, other, array_op)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\ops.py:63\u001b[0m, in \u001b[0;36moperate_blockwise\u001b[1;34m(left, right, array_op)\u001b[0m\n\u001b[0;32m     61\u001b[0m res_blks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lvals, rvals, locs, left_ea, right_ea, rblk \u001b[38;5;129;01min\u001b[39;00m _iter_block_pairs(left, right):\n\u001b[1;32m---> 63\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m array_op(lvals, rvals)\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m left_ea \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m right_ea \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(res_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     65\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:232\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:178\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m         result \u001b[38;5;241m=\u001b[39m _masked_arith_op(left, right, op)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:116\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 116\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m op(xrav[mask], yrav[mask])\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "bow = get_bag_of_words_matrix(tweets_list)\n",
    "df - get_bag_of_words_dataframe(tweets_list)\n",
    "\n",
    "cluster = GaussianMixture(n_components=3)\n",
    "cluster.fit(bow)\n",
    "\n",
    "labels = cluster.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'tweets': tweets_list,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First cluster with cosine similarity as the distance measure..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
